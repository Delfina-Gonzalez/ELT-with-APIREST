{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3bddc8",
   "metadata": {},
   "source": [
    "# üöÄ Proyecto ELT con SpaceX API  \n",
    "## Notebook 01 ‚Äì Extracci√≥n y Carga\n",
    "\n",
    "En este notebook se realiza la **extracci√≥n de datos desde la API p√∫blica de SpaceX** y el **almacenamiento en Delta Lake**.  \n",
    "\n",
    "Se siguen los pasos de la consigna:  \n",
    "1. Extracci√≥n de **2 o m√°s endpoints**.  \n",
    "2. Uso de al menos un **endpoint din√°mico (actualizable)** y otro **est√°tico**.  \n",
    "3. Guardado en **formato Delta Lake**.  \n",
    "4. Aplicaci√≥n de **extracci√≥n incremental y full** seg√∫n corresponda.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6a3062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root detectado en: c:\\Users\\MONSO\\OneDrive\\Escritorio\\Final-DataEngineering\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CELDA DE CONFIGURACI√ìN INICIAL\n",
    "# =========================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# --- RUTA DEL PROYECTO ---\n",
    "# Detecta autom√°ticamente la ra√≠z del proyecto buscando la carpeta \"src\"\n",
    "def find_project_root(marker=\"src\"):\n",
    "    path = Path().cwd()\n",
    "    for _ in range(5):  # sube hasta 5 niveles si es necesario\n",
    "        if (path / marker).exists():\n",
    "            return path\n",
    "        path = path.parent\n",
    "    raise FileNotFoundError(f\"No se encontr√≥ la carpeta '{marker}' en los niveles superiores.\")\n",
    "\n",
    "project_root = find_project_root()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root detectado en: {project_root}\")\n",
    "\n",
    "# --- IMPORTS DEL PROYECTO ---\n",
    "from src.extract import fetch_data\n",
    "from src.load import save_to_parquet\n",
    "from src.config import setup_logger\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785af7dd",
   "metadata": {},
   "source": [
    "## üîó Endpoints seleccionados\n",
    "\n",
    "- **Din√°micos:**  \n",
    "  - `launches/upcoming` ‚Üí Pr√≥ximos lanzamientos.  \n",
    "\n",
    "- **Est√°ticos:**  \n",
    "  - `rockets` ‚Üí Informaci√≥n de cohetes.  \n",
    "  - `dragons` ‚Üí Informaci√≥n de c√°psulas Dragon.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a0c7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 21:30:08,815 - INFO - Extrayendo Rockets (FULL)...\n",
      "2025-09-06 21:30:12,208 - INFO - Extrayendo Dragons (FULL)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracci√≥n completa: 4 rockets extra√≠dos.\n",
      "‚úÖ Extracci√≥n completa: 2 dragons extra√≠dos.\n"
     ]
    }
   ],
   "source": [
    "# Extracci√≥n FULL de endpoints est√°ticos\n",
    "logger.info(\"Extrayendo Rockets (FULL)...\")\n",
    "rockets_df = fetch_data(\"rockets\")\n",
    "print(f\"‚úÖ Extracci√≥n completa: {len(rockets_df)} rockets extra√≠dos.\")\n",
    "\n",
    "logger.info(\"Extrayendo Dragons (FULL)...\")\n",
    "dragons_df = fetch_data(\"dragons\")\n",
    "print(f\"‚úÖ Extracci√≥n completa: {len(dragons_df)} dragons extra√≠dos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fddc6743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 21:30:13,616 - INFO - Extrayendo Upcoming Launches (INCREMENTAL)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracci√≥n completa: 18 nuevos lanzamientos extra√≠dos.\n"
     ]
    }
   ],
   "source": [
    "# Extracci√≥n INCREMENTAL de upcoming launches\n",
    "logger.info(\"Extrayendo Upcoming Launches (INCREMENTAL)...\")\n",
    "\n",
    "# Extracci√≥n de datos nuevos\n",
    "launches_new = fetch_data(\"upcoming_launches\")\n",
    "\n",
    "print(f\"‚úÖ Extracci√≥n completa: {len(launches_new)} nuevos lanzamientos extra√≠dos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582e388",
   "metadata": {},
   "source": [
    "## üíæ Guardado\n",
    "\n",
    "Se guarda cada DataFrame en formato **Delta Lake**:  \n",
    "- Los **endpoints din√°micos** (`upcoming_launches`) se almacenan con **particiones por fecha (extracci√≥n incremental)**.  \n",
    "- Los **endpoints est√°ticos** (`rockets`, `dragons`) se guardan en una √∫nica ruta (extracci√≥n full).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f948bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_partition_path() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Guardado de datos en Parquet\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Carga de datos con un \"modo full\" en formato Parquet\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43msave_to_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrockets_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrockets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbronze\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m save_to_parquet(dragons_df, \u001b[33m\"\u001b[39m\u001b[33mdragons\u001b[39m\u001b[33m\"\u001b[39m, layer=\u001b[33m\"\u001b[39m\u001b[33mbronze\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# INCREMENTAL save de Launches\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MONSO\\OneDrive\\Escritorio\\Final-DataEngineering\\src\\load.py:27\u001b[39m, in \u001b[36msave_to_parquet\u001b[39m\u001b[34m(df_new, endpoint_name, incremental, layer, mode, key_col)\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Determinar la ruta base del endpoint\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Si incremental es False, siempre guardaremos en la carpeta \"full\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m path = \u001b[43mget_partition_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m Path(path).mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Construir la ruta del archivo principal\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: get_partition_path() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# Guardado de datos en Parquet\n",
    "\n",
    "# Carga de datos con un \"modo full\" en formato Parquet\n",
    "save_to_parquet(rockets_df, \"rockets\", layer=\"bronze\")\n",
    "save_to_parquet(dragons_df, \"dragons\", layer=\"bronze\")\n",
    "\n",
    "# INCREMENTAL save de Launches\n",
    "if not launches_new.empty:\n",
    "    print(f\"‚úÖ Extracci√≥n completa: {len(launches_new)} launches nuevos extra√≠dos.\")\n",
    "    # Guardar solo los datos incrementales\n",
    "    save_to_parquet(launches_new, \"upcoming_launches\", layer=\"bronze\", incremental=True)\n",
    "else:\n",
    "    logger.info(\"No hay datos nuevos para upcoming_launches\")\n",
    "\n",
    "logger.info(\"Todos los datasets fueron guardados correctamente en Parquet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
